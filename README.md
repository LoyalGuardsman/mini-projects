A collection of seven bite-sized Python exercises designed to reinforce key data-engineering and scripting skills. Each folder is a standalone utility that tackles a real-world task—from parsing logs to building ETL pipelines and simple DAG simulations.

## Included Projects

1. **Log Parser**  
   Read server logs, count INFO/ERROR/WARNING entries, find the most frequent error, and group activity by hour.

2. **Data Formatter**  
   Practice flexible report generation using `*args` and `**kwargs` to format data into custom tables or summaries.

3. **CSV Transformer**  
   Clean and reshape CSV data using `pandas`, covering filtering, renaming, type conversions, and aggregation.

4. **Simple ETL Flow**  
   Ingest JSON from a public API, transform records, and load them into an SQLite database with Python.

5. **PySpark Starter**  
   Run a word-count or basic aggregation job on a sample dataset using PySpark’s RDD/DataFrame APIs.

6. **Airflow Sim**  
   Mock up a lightweight DAG runner in pure Python to understand task dependencies and scheduling logic.

7. **Trigger-Based News Alert Pipeline**  
   Fetch the latest headlines via an API, clean JSON payloads, and send real-time notifications when keywords appear.
